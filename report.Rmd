---
title: "Practical Machine Learning Course Project"
author: "Chan Sing EU"
date: "Sunday, March 22, 2015"
output: 
        html_document:
                fig_height: 9
                fig_width: 9
---

## Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.

## Objective
In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. Our goal is to predict the manner in which they did the exercise. 

## Load Libraries  
```{r, cache = TRUE}
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(ROCR)
```

```{r, cache =TRUE}
#optional: set multicore
library(cluster)
library(parallel)
library(doSNOW)
coreNumber=max(detectCores(),1)
cluster=makeCluster(coreNumber, type = "SOCK",outfile="")
registerDoSNOW(cluster)
```

## Download Data
```{r, cache = TRUE}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method = "auto")
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method = "auto")
}
```  

## Read Data
We will read the two downloaded csv files into two data frames and replace missing values with "NA".

```{r, cache = TRUE}
trainRaw <- read.csv("./data/pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
testRaw <- read.csv("./data/pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
dim(trainRaw)
dim(testRaw)
```

The training dataset has 19,622 observations with 160 variables each, and the testing dataset has 20 observations and 160 variables. The outcome to predict is the **"classe"** variable in the training dataset.

## Clean Data
First, we remove columns that contain NA missing values.

```{r, cache = TRUE}
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0] 
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0] 
```

Next, we remove columns that are irrelevant for our model fitting.
The following variables will be removed:
**user_name**, **raw_timestamp_part_1**, **raw_timestamp_part_2**, **cvtd_timestamp**, **new_window**, and  **num_window** (columns 1 to 7)

```{r, cache = TRUE}
trainCleaned <- trainRaw[,-c(1:7)]
testCleaned <- testRaw[,-c(1:7)]
```

The cleaned training dataset now has 19,622 observations with 53 variables, and the testing dataset has 20 observations and 53 variables.

### Slice Training Dataset
We will now split the cleaned training dataset into a pure training dataset (70%) and a validation dataset (30%). The validation dataset will be used for cross validation later.  

```{r, cache = TRUE}
set.seed(12321)

inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=FALSE)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
dim(trainData)
dim(testData)
```

The trainData has 13,737 observations for model fitting and the testData has 5,885 observations to validate and estimate performance of prediction model later.

## Model Fitting
We will use **Random Forest** algorithm to fit a predictive model for the training dataset because it can perform robust selection of predictors. We will apply **10-fold cross validation** to the algorithm.

```{r, cache = TRUE}
controlRf <- trainControl(method="cv", number=10)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf)
modelRf
```

Next, we estimate the performance of the model on the validation dataset.  

```{r, cache = T}
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)
```

```{r, cache = T}
accuracy <- postResample(predictRf, testData$classe)
accuracy
oose <- 1 - as.numeric(confusionMatrix(testData$classe, predictRf)$overall[1])
oose
```

The estimated accuracy of the prediction model using Random Forest algorithm is **99.51%** and the estimated out-of-sample error is **0.49%**.

## Predict for Test Dataset
We will now apply our model to our original 20 test records.  
```{r, cache = TRUE}
results <- predict(modelRf, testCleaned)
results
```

## Submission
We will now generate the required text files for submission.

```{r, cache = TRUE}
if (!file.exists("./results")) {
  dir.create("./results")
}
# Write files for submission
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./results/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(results)
```

## Appendix
### 1. Decision Tree 

```{r, cache = TRUE}
tree <- rpart(classe ~ ., data=trainData, method="class")
prp(tree)
```